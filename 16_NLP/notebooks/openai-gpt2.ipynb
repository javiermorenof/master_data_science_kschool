{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# install the requirements\n",
    "# pip install torch torchvision\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modelos de Lenguaje de OpenAI\n",
    "\n",
    "A mitad de febrero, [OpenAI publicó un modelo de lenguaje](https://blog.openai.com/better-language-models/) capaz de generar lenguaje natural de formar coherente. Este modelo es generalista y, a pesar de ello, es capaz de rivalizar con los mejores sistemas específicos en tareas como comprensión automática de lenguaje natural, traducción automática, búsqueda de respuestas y resumen automático.\n",
    "\n",
    "Este modelo, llamado GPT-2, es el resultado de haber entrenado con 8 millones de páginas web (40 GB) con 1 500 millones de parámetros con un único objetivo: predecir cuál es la siguiente palabra.\n",
    "\n",
    "Sin embargo, OpenAI no ha publicado el modelo para evitar que alguien con malas intenciones pueda hacer un uso dañino de esta tecnología. Sí que han publicado una versión simplificada y más pequeña, y el paper [\"Language Models are Unsupervised Multitask Learners\"](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), en el que explican todo el proceso.\n",
    "\n",
    "Con ganas y GPUs suficientes (+ tiempo y dinero), se puede replicar el proceso. Otras lecturas interesantes, sobre el tema: \n",
    "\n",
    "- [OpenAI's new Multitalented AI Writes, Translates, and Slanders](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2)\n",
    "- [Some thoughts on zero-day threats in AI, and OpenAI's GP2](https://www.fast.ai/2019/02/15/openai-gp2/)\n",
    "\n",
    "\n",
    "Este código de ejemplo está inspirado en [un tweet de Thomas Wolf](https://twitter.com/Thom_Wolf/status/1097465312579072000), de [Hugging Face](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416d4b5a258e447794aec01b22e26e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a9c05631584f95a5b957f535bcb1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1d705198f34cc3888a7a20411a35d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da130076c964892869c8bafdfdc63f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación, definimos una función para:\n",
    "\n",
    "1. tokenizar el texto de entrada y codificarlo como un vector con los pesos obtenidos por el modelo GPT2\n",
    "2. predecir la siguiente palabra más frecuente\n",
    "3. decodificar el vector como una secuencia de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def generate(text, length=50):\n",
    "    \"\"\"Generate automatic Natural Language from the input text\"\"\"\n",
    "    vec_text = tokenizer.encode(text)\n",
    "    my_input, past = torch.tensor([vec_text]), None\n",
    "\n",
    "    for _ in range(length):\n",
    "        logits, past = model(my_input, past=past)\n",
    "        my_input = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "        vec_text.append(my_input.item())\n",
    "\n",
    "    return tokenizer.decode(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only think we can do to fight climate change is by getting more corporations and government to do their jobs to deal with it.\"\n",
      "\n",
      "Shape Created with Sketch. In pictures: Climate change in the US Show all 43 left Created \n",
      "\n",
      "The only think we can do to fight climate change is to put it fully into being… We need to start tackling the issue now.\"\n",
      "\n",
      "On Friday, Secretary for Energy Mark Carney promised environmentally sound decisions after the economy as a \n",
      "\n",
      "The only think we can do to fight climate change is test nuclear power. This is something Marco Rubio certainly couldn't do. That is the civil rights movie we live in he created,\" Stemmdtkov said.\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defino un texto de entrada\n",
    "text = \"The only think we can do to fight climate change is\"\n",
    "\n",
    "# y generamos automáticamente las secuencias más probables\n",
    "for _ in range(3):\n",
    "    print(generate(text, 35), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was born in Spain so I speak Spanish\n",
      "I was born in France so I speak Spanish\n",
      "I was born in Italy so I speak Italian\n",
      "I was born in Greece so I speak Greek\n",
      "I was born in Russia so I speak only\n",
      "I was born in China so I speak Mandarin\n",
      "I was born in Japan so I speak the\n",
      "I was born in India so I speak Beng\n"
     ]
    }
   ],
   "source": [
    "countries = \"Spain France Italy Greece Russia China Japan India\".split()\n",
    "\n",
    "for country in countries:\n",
    "    text = f\"I was born in {country} so I speak\"\n",
    "    print(generate(text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
