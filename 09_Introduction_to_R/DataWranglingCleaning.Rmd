---
title: "Manejo y limpieza de datos"
author: "FSC"
#date: "June 7, 2019"
output:
  pdf_document: 
    toc: true
    toc_depth: 5
  html_document: 
    toc: true
    toc_depth: 5
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dslabs)
library(devtools)
library(rvest)
library(janitor)
library(ggplot2movies)
#options(encoding = 'UTF-8')
```

# Antes de empezar...

Los materiales de esta clase han sido preparados utilizando dos libros que están disponibles bajo licencia OUP y que os invito a explorar: 
  
  *Hands-on programming with R* https://rstudio-education.github.io/hopr/
  
  *Data Science with R* https://rafalab.github.io/dsbook/

# El ecosistema *tidyverse*

Se trata de una colección de paquetes de R diseñados por Hadley Wickham específicamente para data science. Todos los paquetes comparten la misma filosofia, diseño, gramática y estructura. 

<center>
![Tidyverse](C:/Users/fscabo/Desktop/MasterDataScience_KSchool/Session3_DataWranglingCleaning/tidyverse.png)

Todos los paquetes de *tidyverse* pueden instalarse de una vez con:
```{r}
#install.packages("tidyverse")
```

## Ejemplo motivacional: Gapminder foundation

La organización Gapminder trata de desenmascarar falsos mitos acerca del estado del mundo en terminos de pobreza, desigualdad, etc a través del uso de datos. Utilizando el dataset *gapminder* del paquete *dslabs* trataremos de contestar a dos preguntas: 

  1. Es cierto que el mundo se divide en paises occidentales ricos y no-occidentales pobres?
  2. Han aumentado las diferencias entre paises en los últimos 40 años?
  
* Descargamos los datos:
```{r}
library(dslabs)
data(gapminder)
#si no tienes el paquete instalado
#gapminder=read.csv("DataSets/Gapminder.csv")
```

*Exploramos los datos:
```{r, echo=FALSE}
View(gapminder)
head(gapminder)
str(gapminder)
```

* De las siguientes parejas, cual dirias que tuvo la mayor mortalidad infantil en 2015?

++ Sri Lanka or Turkey
```{r}
SL = gapminder[(gapminder$year == 2015 & gapminder$country == "Sri Lanka"),]
TK = gapminder[(gapminder$year == 2015 & gapminder$country == "Turkey"),]
SL
TK
```
++ Poland or South Korea

++ Malaysia or Russia

++ Pakistan or Vietnam

++ Thailand or South Africa

Ahora, trata de responderlo usando los datos por medio de los comandos *filter* y *select*

## Paquete dplyr: *filter* y *select*

*filter* se encarga de hacer _subsetting_ de un data.frame, tibble o matriz mientras que *select* selecciona las columnas. Como cualquier otra función tidyverse el primer argumento tiene que ser el objeto que se va a manipular. A continuacion con *filter* se da una condicion logica que devuelve TRUE or FALSE para cada fila. Para *select* es suficiente con dar el nombre de la columna pero tambien pueden proporcionarse funciones como *starts_with()*, *ends_with()* o *contain()*. Si se quiere quitar una columna basta con poner un "-" delante.

Por ejemplo, usando filter and select podemos quedarnos solo con la informacion de mortalidad infantil en cada pareja de paises en el año 2015:

```{r}
library(dplyr)
gapminder %>% 
  filter(year == 2015 & country %in% c("Sri Lanka","Turkey")) %>% 
  select(country, infant_mortality)

gapminder %>% 
  filter(year == 2015 & country %in% c("Poland","South Korea")) %>%
  select(country, infant_mortality)
gapminder %>% 
  filter(year == 2015 & country %in% c("Malaysia","Russia")) %>% 
  select(country, infant_mortality)
gapminder %>% 
  filter(year == 2015 & country %in% c("Pakistan","Vietnam")) %>% 
  select(country, infant_mortality)
gapminder %>% 
  filter(year == 2015 & country %in% c("Thailand","South Africa")) %>% 
  select(country, infant_mortality)

```
Si queremos centrarnos en los paises de una cierta región para ver por ejemplo la media pero no nos acordamos del nombre exacto de la columna:
```{r}
gp.reduced<-gapminder %>% 
  filter(year == 2015 ) %>% 
  select(country, starts_with("reg"), infant_mortality)

head(gp.reduced)
```

## Sumarizando data con *dplyr()*

### *summarize()*
Vamos a utilizar los datos de alturas del paquete dslabs
```{r}
library(dslabs)
data(heights)
head(heights)
str(heights)
```
La función *summarize()* del paquete *dplyr* nos calcula cualquier agregado que le pidamos de un vector de un data.frame o de un tibble. Como el input era un data.frame() el output también lo es.
```{r}
heights.summary<-heights %>% 
  filter(sex == "Female") %>% 
  summarize(
    average = mean(height),
    standard_deviation = sd(height)
    )
```

Se pueden utilizar medidas mas robustas.

En este sentido, por lo general, la estadística no paramétrica es más robusta que la paramétrica.
El equivalente en estadística paramétrica a la mediana (estadística no paramétrica), es la media; y el equivalente al rango intercuartílico en estadística paramétrica es la desviación estándar.

Por lo tanto:
- Estadística paramétrica:
  - Media
  - Desviación estándar
- Estadística no paramétrica:
  - Mediana
  - Desviación Absoluta de la Mediana
  - Rango intercuartílico (Q3-Q1)
  
```{r}
s <- heights %>%
  summarize(
    median = median(height),
    mad=mad(height),
    min=min(height),
    max=max(height))
s
str(s)
```

Puedo acceder a cada una de esas variables con el $
```{r}
s$max
```
**NOTA: con la función *summarize* solo podemos llamar funciones que devuelvan un solo valor**.

### group_by()

Si queremos hacer una operacion por grupos:
```{r}
heights %>% 
  group_by(sex) %>%
  summarize(
    average = mean(height),
    standard_deviation = sd(height)
    )
```
Cuando se hace un `group_by` el output es un tibble.

### *dot*
Recordemos en el último ejercicio de la sesión II habiamos descargado la tabla con el rate de asesinatos en todo el mundo. 
```{r, eval=TRUE}
library(rvest)

url="https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate"
h <- read_html(url)
class(h)
h
tab <- h %>% html_nodes("table")
tab <- tab[[4]] %>% html_table
head(tab)
class(tab)
#A continuación seleccionamos columnas concretas y columnas que "empiezan por..." y las cambiamos el nombre
tab <- tab %>% 
  select(starts_with("Country"),
         Region,Count,Rate,starts_with("Year")) %>%
  setNames(c("country", "continent", "total", "murder_rate","year"))

head(tab)
```

Para comparar USA (nuestros datos por estados en murders) necesitabamos primero hacer la media de todos los estados, calculando el ratio de asesinatos por 100.000 habitantes: 
```{r}
data(murders)
s <- murders %>% 
  mutate(rate = total/population*100000) %>%
  summarize(average = mean(rate))%>%
  #Mediante el '.' llamo a "murders"
  .$average
s
str(s)
```

Como las funciones de dplyr devuelven el mismo tipo de objeto que su input en este caso queremos acceder sólo al valor que tienen almacenado. Podemos hacerlo asi:
```{r}
s
s$average
s %>% .$average
```

Como se ha explicado, "."  reemplaza al objeto que pasamos por el pipe (murders), con el objetivo de acceder al valor almacenado:
```{r}
s <- murders %>% 
  summarize(rate=mean(total/population*100000)) %>%
  .$rate
s

s2<-murders %>% 
  summarize(total=sum(total)) %>%
  .$total
s2
```


Construimos un objeto que contenga la informacion que teniamos de USA en el objeto tab, quedandonos solo con medidas del año 2015.
Con el '-' que se ponde delante de 'year' se pide que seleccione todas las columnas menos year
```{r}
tab.USA<-tab %>% 
  filter(year=="2015") %>% 
  select(-year) %>%
  #Ojo, debajo se pone un igual porque es una asignación ('add_row'), no una comparación
  add_row(country = "USA", 
          continent = "Americas", 
          total = s2,
          murder_rate=s)

tab.USA
```

¿Cómo puedo ver qué valores hay en 'continent'? De dos maneras, siendo 'unique' la más común
```{r}
#Manera 1. Más usada:
unique(tab$continent)
#Manera 2. La idea feliz -usada para factores-:
levels(as.factor(tab$america))
```

¿Cómo se encuentra EEUU respecto al resto de países de America?
Como se puede ver a continuación, se ha usado `arrange` para ordenar datos:
```{r}
tab.USA %>% filter(continent=="Americas") %>% arrange(murder_rate)
```

### Ordenar data.frames: *arrange()* *top_n()*
¿Cual es el estado con mayor poblacion?
La función *arrange()* ordena tablas enteras por una variable

Nota que la función *desc()* indica que se ordena de manera descendente el data.frame.
```{r}
tab.USA %>% 
  group_by(continent) %>% 
  summarize(mean_rate=mean(murder_rate)) %>% arrange(desc(mean_rate))

tab.USA %>% filter(continent=="Americas") %>% arrange(murder_rate)

```

```{r}
murders %>% arrange(population) %>% head()
```
¿Y con menor numero de asesinatos?

```{r}
murders %>% arrange(total) %>% head()
```

¿Y cada cien mil habitantes?
Mediante `mutate` estoy añadiendo una nueva columna con el murder rate
```{r}
murders %>% mutate(rate=total/population*100000)%>%
  arrange(rate) %>% 
  head()
```

Si tenemos empates podemos usar una segunda columna para deshacer dicho empate:
```{r}
murders %>% mutate(rate=total/population*100000)%>%
  arrange(total,rate) %>% 
  head()
```

¿Y el mayor? Por último podemos seleccionar las primeras filas de un data.frame o de un tibble usando la función *top_n()*.
En el ejemplo de debajo se puede ver que actúa como un `head()`
```{r}
murders %>% mutate(rate=total/population*100000)%>%
  arrange(desc(rate)) %>%
  top_n(10)
```

O calculemos la media
```{r}
murders %>% summarize(avm = mean(rate), avt =mean(total)) %>% .$avm
```
Con el punto estoy haciendo una autoreferencia, le estoy diciendo que de toda la variable que ha creado, me de la columna avm

### Ejercicio: NCHS Data
El National Center for Health Statistics ha realizado encuestas de habitos de vida y salud desde 1960. Desde 1999 5000 individuos han sido entrevistados cada año junto con una exploración medica. Parte de estos datos están en el paquete __NHANES__

```{r}
library(NHANES)
data(NHANES)
```
Los datos en el paquete __NHANES__ contienen una gran cantidad de valores perdidos.Las principales funciones de sumarización de R devuelven un NA si hay NA en los datos. 

```{r}
data(na_example)
mean(na_example)
sd(na_example)
```

Para ignorar los valores perdidos usamos el argumento `na.rm`:

```{r}
mean(na_example, na.rm = TRUE)
sd(na_example, na.rm = TRUE)
```

Vamos a explorar los datos en __NHANES__

1. Tensión sanguínea: Seleccionemos a las mujeres entre 20 y 29 años.`AgeDecade` es una variable categórica que contiene las edades. La categoría es " 20-29", con un espacio delante! Cuál es su media? (`BPSysAve` variable). Guardalo en una variable llamada`ref`.

Hint: Usa `filter` y `summarize` y luego usa `na.rm = TRUE` al calcular su meda y desviacion estandard. Tambien podrias quitar los missing usando `filter`.

```{r}
library(NHANES)
data(NHANES)
ref <- NHANES %>%
  filter(!is.na(AgeDecade)) %>%
  #Ojo, no pongo c(Gender,AgeDecade) porque no estoy concatenando vectores
  group_by(Gender, AgeDecade) %>%
  summarize(avgSys=mean(BPSysAve, na.rm=TRUE), avgDia=mean(BPDiaAve, na.rm=TRUE))
ref
```

2. Usando pipe asigna ese valor a una variable llamada `ref_avg`. Hint: Use the code similar to above and then `pull`.

3. min y max para cada grupo de edad dentro de las mujeres

```{r}
set <- NHANES %>%
  filter(Gender == "female") %>%
  summarize(maxSys=max(BPSysAve, na.rm=TRUE), maxDia=max(BPDiaAve, na.rm=TRUE), minSys=min(BPSysAve, na.rm=TRUE), minDia=min(BPDiaAve, na.rm=TRUE))
set
```

4. Media y desviacion estandar para cada grupo de edad. Hint: filtra por genero y luego usa `group_by`.

```{r}
set2 <- NHANES %>%
  group_by(Gender) %>%
  summarize(avgSys=mean(BPSysAve, na.rm=TRUE), avgDia=mean(BPDiaAve, na.rm=TRUE), sdSys=sd(BPSysAve, na.rm=TRUE), sdDia=sd(BPDiaAve, na.rm=TRUE))
set2
```


5. Hacer lo mismo para los hombres 

6. Usando `group_by(AgeDecade, Gender)`, repite 4 y 5 con una sola linea de código.

7. Para los hombres entre 40-49 compara su presion sistolica para las distintas razas reportadas en la variable `Race1` y ordenalas de mayor a menor. 


## Tidyverse conditionals

### `case_when`
Es la manera de hacer 'if' y 'else if' y 'else' de dplyr. Es muy sencilla.
El TRUE equivale a ELSE, es decir, que para el resto devuelva 0.
```{r}
x <- c(-2, -1, 0, 1, 2)
case_when(x < 0 ~ "Negative", 
          x > 0 ~ "Positive", 
          TRUE ~ "Zero")
```

Imaginemos que queremos comparar los rates de asesinatos en tres regiones: _New England_, _West Coast_, _South_,  y _other_. Para cada estado necesitamos preguntar si es de cada uno de ellos y si no pasar al siguiente:

```{r}
data(murders)
murders %>% 
  mutate(group = case_when(
    abb %in% c("ME", "NH", "VT", "MA", "RI", "CT") ~ "New England",
    abb %in% c("WA", "OR", "CA") ~ "West Coast",
    region == "South" ~ "South",
    TRUE ~ "other")) %>%
  group_by(group) %>%
  summarize(rate = sum(total) / sum(population) * 10^5) %>%
  arrange(rate)
```

### `between`

```{r, eval=FALSE}
x >= a & x <= b
```

Utilizando tidyverse:

```{r, eval = FALSE}
between(x, a, b)
```


## *Tidy* data
Los datos están en formato tidy si la información de una o varias columnas constituyen una clave única para cada dato, frente a los datos de tipo "wide" para los que dicha clave viene dada por los nombres o identificadores de filas y columnas, haciendo complicado tener claves constituidas por mas de tres campos. En el momento en el que queremos trabajar con ggplot, el dataset debe ser tidy. Tidy, en el fondo, hace referencia al formato.

Generalmente trabajaremos en formato tidy, aunque si queremos hacer una tabla de contingencia utilizaremos formato wide.

*gapminder* es un data.frame *tidy*: para cada pais y año tenemos información de varios indicadores como mortalidad infantil, fertilidad, esperanza de vida, etc. 

Fácilmente, gracias a que los datos están en formato *tidy* podemos usar el paquete ggplot2 para comparar la evolucion de la fertilidad y la esperanza de vida en Europa y Asia y así responder a las preguntas que teníamos: 
```{r}
library(ggplot2)
years <- c(1962, 1980, 1990, 2000, 2012)
continents <- c("Europe", "Asia")
gapminder %>% 
  filter(year %in% years & continent %in% continents) %>%
  ggplot(aes(fertility, life_expectancy, col = continent)) +
  geom_point() +
  facet_wrap(~year) 
```
Viendo este plot parece que las diferencias entre Asia y Europa han ido desapareciendo con el paso de los años. 

Centrémonos ahora sólo en el indicador de fertilidad de un pais, USA:
```{r}
gapminder %>% 
  filter(country == "United States") %>% 
  ggplot(aes(year,fertility)) +
  geom_line()
```
Centrémonos en comparar Alemania y South Korea
```{r}
tidy_data <- gapminder %>% 
  filter(country %in% 
         c("South Korea", "Germany","United States")) %>%
  select(country, year, fertility)

head(tidy_data)
```
```{r}
tidy_data %>% 
  ggplot(aes(year, fertility, color = country)) +
  geom_point()
```  

### *pivot_longer* and *pivot_wider*

Todo esto ha sido posible porque gapminder contiene la información en un formato tidy. Irizarry y sus colegas han hecho un gran esfuerzo para poder tener los datos limpios y en este formato. Cómo podemos transformar datos *wide* en datos *tidy*? Utilizando la función *gather* o mejor aun, su sustituta *pivot_longer()*

Primero leemos los datos en formato *tibble*. En el ejemplo de debajo tenemos el formato wide.
```{r}
path <- system.file("extdata", package="dslabs")
filename <- file.path(path,  "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
wide_data
#como ejemplo: seleccionamos las primeras 9 columnas por nombre
select(wide_data, country, `1960`:`1967`)
```
La funcion *pivot_longer()* va a "normalizar" los datos en las columnas que le digamos (`1960`:`2015`) preservando la información del resto de columnas de la matriz. 

Los primeros valores que le damos es el nombre del "key" (y se pone '-country' porque no quiero que realice la trasposición a esta columna, es decir, no quiero que pivote) y el nombre para el "value".


```{r}
new_tidy_data <- wide_data %>%
  pivot_longer(-country,
               names_to = "year",
               values_to = "fertility")
new_tidy_data
```
A veces se necesita volver de tidy data a wide data usando *pivot_wider()*

```{r}
new_wide_data <- new_tidy_data %>% 
    pivot_wider(everything(),
              names_from=year, 
              values_from=fertility)
select(new_wide_data, country, `1960`:`1967`)
```

#### Si los nombres de las columnas son numericos
Aquí es igual: pedimos que pivote las variables que empiezan con "wk".
```{r}
billboard
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

Ahora queremos convertir la variable semana en numerica
```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week",
    #Con names_prefix indico qué prefijo quiero que me quite de ahora en adelante
    names_prefix = "wk",
    #Con ptypes indico el tipo de la columna
    names_ptypes =list(week = integer()),
    values_to = "rank",
    values_drop_na = TRUE
  )
```

```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    names_ptypes = list(week = integer()),
    values_to = "rank",
    values_drop_na = TRUE)%>%
  select(week)
```

#### Variables dentro de los nombres de columna
```{r}
who
```

```{r}
who %>% 
pivot_longer(
  #Seleccion de rango de columnas que se van a pivotar
  cols = new_sp_m014:newrel_f65,
  #Nombres que van a tener las columnas
  names_to = c("diagnosis", "gender", "age"), 
  #Uso de RegEx para extraer valores. Cada parte entre paréntesis corresponde a cada una de las columnas de la línea superior (por orden). Se explica debajo en detalle:
  names_pattern = "new_?(.*)_(.)(.*)",
  values_to = "count"
)
```

En names pattern se pone mediante una expresión regular el patrón que va a usar para separar entre los grupos de 'names_to'. La expresión regular consta de estas partes:
- "new_?". Busca "new_", peor el último caracter puede estar o no, como marca la interrogación, pero lo descarta, ya que no está entre paréntesis.
- (.*). La siguiente parte, como está entre paréntesis, coge tantos elementos como encuentre hasta el siguiente guión (que ya está fuera del paréntesis). Esta parte extaída la meterá en diagnosis, ya que es el primer grupo que coge.
- (.). Luego coge un único caracter, que hace referencia al género
- (.*). Luego coge tantos caracteres como encuentre
```{r}
who %>% 
pivot_longer(
  cols = new_sp_m014:newrel_f65,
  names_to = c("diagnosis", "gender", "age"), 
  names_pattern = "new_?(.*)_(.)(.*)",
  names_ptypes = list(
    gender = factor(levels = c("f", "m")),
    age = factor(
      levels = c("014", "1524", "2534", "3544", "4554", "5564", "65"), 
      ordered = TRUE
    )
  ),
  values_to = "count"
)
```

#### Varias observaciones por fila
```{r}
View(anscombe)
anscombe %>%
 pivot_longer(everything(),
   names_to = c(".value", "set"),
   names_pattern = "(.)(.)"
 )
```

Otro ejemplo: 

```{r}
path <- system.file("extdata", package = "dslabs")
filename <- file.path(path, "life-expectancy-and-fertility-two-countries-example.csv")

raw_dat <- read_csv(filename)
# lo transformamos en data tidy
dat <- raw_dat %>% 
  pivot_longer(-country,
               names_to = "key",
               values_to="value")
head(dat)
# pero tenemos dos observaciones (año&variable) en cada fila
dat <- raw_dat %>% 
  pivot_longer(-country,
               names_to = c("year", "variable"),
               names_pattern = "(.{4})_(.*)",
               names_ptypes = list(
                 year = integer(),
                 variable=factor(
                   levels=c("fertility","life_expectancy"))
                 ),
  values_to = "value"
 )

#Ahora se va a pasar a wide fertility y life_expectancy para que la tabla nos quede tidy totalmente
tidy_dat2 <- dat %>%
  #Selecciono todas las columnas
  pivot_wider(everything(),
              #Los nombres van a venir de f_t
              names_from = variable,
              #Los valores se tomar?n de value
              values_from = value)

tidy_dat2
```

### Ejercicios: tidy/wide

1. Niveles de CO2.

Definimos los datos de CO2 en formato wide:
```{r}
? co2
View(co2)
co2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>% 
  setNames(1:12) %>%
  mutate(year = as.character(1959:1997))
View(co2_wide)
```

Utiliza la función *pivot_longer* para reordenar este objeto en formato *tidy*. Llama CO2 a la columna con las mediciones de co2 y mes a la columna de los meses. El objeto se llamará co2_tidy.

```{r}
co2_tidy <- co2_wide %>% pivot_longer(-year,
                                 names_to = "month",
                                 values_to = "co2",
                                 names_ptypes = list(co2 = integer()))
co2_tidy
```

Intentamos usarlo para plotear las series temporales

No es capaz de hacer el plot porque month no es un numérico. Rehaz el objeto asegurandote de que month es numérico.


Que nos dice este plot?

  A. Los niveles de CO2 aumentan monotonicamente de 1959 a 1997.

  B. Los niveles de CO2 son mas altos en verano y la media anual aumento de 1959 a 1997.

  C. Los niveles de CO2 son constantes y variabilidad aleatoria es lo que explica las diferencias. 

  D. Los niveles de CO2 no tienen una tendencia estacional. 

2. Porcentaje de admision de hombres y mujeres
Utilizando los datos del paquete dslabs:

```{r}
admissions

admissions_wide <- admissions %>% pivot_wider(major,
  names_from=gender,
  values_from=c(admitted,applicants))

admission_percent <- admissions_wide %>% mutate("percentage_admitted_men" = (admitted_men)/(admitted_men + applicants_men)*100,
                                                "percentage_admitted_women" = (admitted_women)/(admitted_women + applicants_women)*100)

admission_selected <- admission_percent %>% select(major, percentage_admitted_men, percentage_admitted_women)
admission_selected
```
* Transformalo usando *pivot_longer()*, una fila para cada major.

* Usa gather para crear un tmp data.frame con una columna que contenga el tipo de información (aplicant/admitted).


* Usa unite para crear la columna column_name i que contenga la informacion de  admitted_men, admitted_women, applicants_men and applicants_women

* Usa spread para generar los datos tidy con cuatro variables para cada major

* Usa %>% para escribir una sola linea de codigo que convierta 
admissions en la tabla tidy final. 

3. Tibble family: convierte los datos en tidy
```{r}
family <- tribble(
  ~family,  ~dob_child1,  ~dob_child2, ~gender_child1, ~gender_child2,
       1L, "1998-11-26", "2000-01-29",             1L,             2L,
       2L, "1996-06-22",           NA,             2L,             NA,
       3L, "2002-07-11", "2004-04-05",             2L,             2L,
       4L, "2004-10-10", "2009-08-27",             1L,             1L,
       5L, "2000-12-05", "2005-02-28",             2L,             1L,
)
family
family <- family %>% mutate_at(vars(starts_with("dob")), parse_date)
family
```
```{r, echo=F}
family %>% 
  pivot_longer(
    -family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

# Limpieza de datos: el paquete janitor

```{r}
library(janitor)
test_df <- as.data.frame(matrix(ncol = 6))
names(test_df) <- c("firstName", "ábc@!*", "% successful (2009)",
                    "REPEAT VALUE", "REPEAT VALUE", "")

test_df %>%
  clean_names()

make.names(names(test_df))
```
## tabyl better than table: adorn_() functions 

__tabyl__ es la alternativa en el universo tidyverse a table. Es un tipo de objeto que vais a usar mucho como data scientists. Cuenta combinaciones de 1,2,3 variables de una forma mas eficiente que table. Una vez creada la tabla podemos formatearla como queramos usando adorn_* functions 

Problemas de table:
  
  * No acepta data.frame inputs y no combina bien con %>%
  * No produce data.frames
* Su resultado es dificil de formatear

_tabyl()_ que forma parte del paquete *janitor* soluciona estos problemas. Ademas funciona con vectores y no cuenta los NAs.
x <- c("big", "big", "small", "small", "small", NA)
tabyl(x)
```

### Ejemplo 1: mtcars
```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns() %>%
  adorn_title()
```
adorn() se puede llamar en todo tipo de objetos, no solo en un tabyl()

```{r}
mtcars %>% adorn_totals("col") %>% adorn_percentages("col") %>% head()
```

### Ejemplo 2: starwars
```{r}
humans <- starwars %>%
  filter(species == "Human")

t1 <- humans %>%
  tabyl(eye_color)
```
```{r}
t1 %>%
  adorn_totals("row") %>%
  adorn_pct_formatting()
```
Se pueden ademas producir tablas de contingencia con tabyl
```{r}
t2 <- humans %>%
  tabyl(gender, eye_color)

t2 %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns()
```
Tablas con 3 variables tabyl
```{r}
t3 <- humans %>%
  tabyl(eye_color, skin_color, gender)
```

```{r}
humans %>%
  tabyl(eye_color, skin_color, gender, show_missing_levels = FALSE) %>%
  adorn_totals("row") %>%
  adorn_percentages("all") %>%
  adorn_pct_formatting(digits = 1) %>%
  adorn_ns %>%
  adorn_title
```

Se pueden presentar tablas de manera incluso mas elegante usando kable del paquete knitr
```{r}
humans %>%
  tabyl(gender, eye_color) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("row") %>% 
  adorn_pct_formatting(rounding = "half up", digits = 0) %>%
  adorn_ns() %>%
  adorn_title("combined") %>%
  knitr::kable()
```

### Ejemplo 3: Modelos de coches
```{r}
mpg_by_cyl_and_am <- mtcars %>%
  group_by(cyl, am) %>%
  summarise(mpg = mean(mpg)) %>%
  spread(am, mpg)

mpg_by_cyl_and_am

mpg_by_cyl_and_am %>%
  adorn_rounding() %>%
  adorn_ns(
    ns = mtcars %>% # calculate the Ns on the fly by calling tabyl on the original data
      tabyl(cyl, am)
  ) %>%
  adorn_title("combined", row_name = "Cylinders", col_name = "Is Automatic")
```

## Otras funciones del paquete janitor

### __get_dupes()__
```{r}
get_dupes(mtcars, wt, cyl)
```

### __get_dupes()__
```{r}
# remove_empty() rows and columns

q <- data.frame(v1 = c(1, NA, 3),
                v2 = c(NA, NA, NA),
                v3 = c("a", NA, "b"))
q %>%
  remove_empty(c("rows", "cols"))
```

### __round_half_up()__
```{r}
nums <- c(2.5, 3.5)
round(nums)
round_half_up(nums)
```

### factores
```{r}
# Count factor levels in groups of high, medium, and low with top_levels()

f <- factor(
  c("strongly agree", "agree", "neutral", "neutral", "disagree", "strongly agree"),
  levels = c("strongly agree", "agree", "neutral", "disagree", "strongly disagree"))
top_levels(f)

top_levels(f, n = 1)
```

## Map-reduce using R
```{r}
library(purrr)
mtcars %>%
  split(.$cyl) %>% # from base R
  map(~ lm(mpg ~ wt, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared")
```
